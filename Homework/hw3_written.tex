\documentclass[11pt, answers]{exam}
\usepackage[margin=1in]{geometry}
\usepackage{amsfonts, amsmath, amssymb, amsthm}
\usepackage{mathtools}
\usepackage{enumerate}
\usepackage{listings}
\usepackage{adjustbox}
\usepackage{cancel}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage[boxed]{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{tikz}
\usepackage{float}
\usepackage{verbatim}

%
% Basic Document Settings
%

% \topmargin=-0.5in
% \evensidemargin=0in
% \oddsidemargin=0in
% \textwidth=6.5in
% \textheight=9.0in
% \headsep=0.25in

% \linespread{1.1}

\geometry{left=2cm,right=2cm,top=2cm,bottom=2cm}

\pagestyle{headandfoot}
\lhead{\hmwkClass\ : \hmwkType\ \#\hmwkNumber\ (Due \hmwkDue)}
\cfoot{\thepage}
% \renewcommand\headrulewidth{0.4pt}
% \renewcommand\footrulewidth{0.4pt}

\setlength\parindent{0pt}

%
% Create Problem Sections
%
\qformat{\hfill}

\newcommand{\hmwkType}{Written}
\newcommand{\hmwkNumber}{3}
\newcommand{\hmwkClass}{VE 492}
\newcommand{\hmwkDue}{June 10rd, 2020 at 11:59pm}


%
% Title Page
%

\title{Homework \hmwkNumber\ \hmwkType}
\date{\hmwkDue}

%
% Various Helper Commands
%

% space of real numbers \R
\newcommand{\R}{\mathbb{R}}

% expected value \EX
\DeclareMathOperator{\EX}{\mathbb{E}}

% For partial derivatives \pderiv{}{}
\newcommand{\pderiv}[2]{\frac{\partial}{\partial #1} (#2)}

% argmax \argmax
\DeclareMathOperator*{\argmax}{arg\,max}

% sign \sign
\DeclareMathOperator{\sign}{sign}

% norm \norm{}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}

% Keys
\newcommand{\key}[1]{\fbox{{\sc #1}}}
\newcommand{\ctrl}{\key{ctrl}--}
\newcommand{\shift}{\key{shift}--}
\newcommand{\run}{\key{run} \ }
\newcommand{\runkey}[1]{\run \key{#1}}
\newcommand{\extend}{\key{extend} \ }
\newcommand{\kkey}[1]{\key{k$_{#1}$}}

\begin{document}
\maketitle

%
% Question 1
%
\begin{questions}
\section{Nash Equilibrium and Iterated Dominance Equilibrium}
\question
\begin{parts}
	\part Show that every iterated dominance equilibrium $s^*$ is a Nash equilibrium.
	
	Suppose $s^*$ is not a Nash equilibrium, which means
	\begin{displaymath}
	\exists i, u_i(s^*) < u_i(s'_i, s^*_{-i}).
	\end{displaymath}
	Then $s'_i$ could not have been removed during the iteration, as it is not dominated by $s^*_i$. Thus we could not get the iterated dominance equilibrium $s^*$, which is a contradiction.
	\part Show by a counter example that not every Nash equilibrium can be generated by iterated dominance.
	
	Consider the following normal form game:
	\begin{table}[htbp]
		\centering
		\begin{tabular}{|c|c|c|}
			\hline
			& A     & B      \\
			\hline
			a     & 1, 1 & -1, -1   \\
			\hline
			b     & -1, -1 & 1, 1  \\
			\hline
		\end{tabular}
	\end{table}

	Here no strategy could be removed, but (a,A), (b,B) are Nash equilibriums.
\end{parts}
\end{questions}

%
% Question 2
%
\begin{questions}
\section{Game in Matrix}
\question
Consider the game with the following bimatrix:
\begin{table}[htbp]
  \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
          & A     & B     & C \\
    \hline
    a     & 1, 1  & 3, x  & 2, 0 \\
    \hline
    b     & $2x$, 3 & 2, 2  & 3, 1 \\
    \hline
    c     & 2, 1  & 1, x  & $x^2$, 4 \\
    \hline
    \end{tabular}
\end{table}
\begin{parts}
	\part Find $x$ so that the game has no pure Nash equilibrium.
	
	$-\sqrt{3} < x < 1$
	\part Find $x$ so that the game has $(c, C)$ as pure Nash equilibrium.
	
	$x \le -\sqrt{3} \ or \ \sqrt{3} \le x \le 4$
\end{parts}
\end{questions}

%
% Question 3
%
\begin{questions}
\section{Nash Equilibrium}
\question
Consider the game in which two players choose nonnegative integers no greater than 1000. Player 1 must choose an even integer, while player 2 must choose an odd integer. When they announce their number, the player who chose the lower number wins the number she announced in dollars. Find the Nash equilibrium.

Solution: 

The normal form representation of the game is:
\begin{table}[htbp]
	\centering
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		& 1     & 3   & $\cdots$  & 999 \\
		\hline
		0     & 0, 0  & 0, 0 & $\cdots$ & 0, 0 \\
		\hline
		2     & -1, 1 & 2, -2 & $\cdots$  & 2, -2 \\
		\hline
		$\cdots$     & $\cdots$  & $\cdots$  & $\cdots$ & $\cdots$ \\
		\hline
		1000     & -1, 1 & -3, 3 & $\cdots$  & -999, 999 \\
		\hline
	\end{tabular}
\end{table}

Hence, the strategy profile (0, 1) at which player 1 chooses 0, and player 2 chooses 1 is a Nash equilibrium.
\end{questions}

%
% Question 4
%
\begin{questions}
\section{MDPs: Dice Bonanza}
\question
A casino is considering adding a new game to their collection, but need to analyze it before releasing it on their floor. 

They have hired you to execute the analysis. On each round of the game, the player has the option of rolling a fair 6-sided die. That is, the die lands on values 1 through 6 with equal probability. Each roll costs 1 dollar, and the player \textbf{must} roll the very first round. Each time the player rolls the die, the player has two possible actions:
\begin{enumerate}[i.]
\item \textit{Stop}: Stop playing by collecting the dollar value that the die lands on;
\item \textit{Roll}: Roll again, paying another 1 dollar.
\end{enumerate}

Having taken VE 492, you decide to model this problem using an infinite horizon Markov Decision Process (MDP). The player initially starts in state \textit{Start}, where the player only has one possible action: \textit{Roll}. State $s_i$ denotes the state where the die lands on $i$. Once a player decides to \textit{Stop}, the game is over, transitioning the player to the \textit{End} state.

\begin{parts}
\part In solving this problem, you consider using policy iteration. Your initial policy $\pi$ is in the table below. Evaluate the policy at each state, with $\gamma = 1$.

\begin{table}[htbp]
  \centering
  \begin{adjustbox}{width=0.8\textwidth}
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    State & $s_1$ & $s_2$ & $s_3$ & \multicolumn{1}{c|}{$s_4$} & \multicolumn{1}{c|}{$s_5$} & \multicolumn{1}{c|}{$s_6$} \\
    \hline
    $\pi(s)$ & Roll  & Roll  & Stop  & \multicolumn{1}{c|}{Stop} & \multicolumn{1}{c|}{Stop} & \multicolumn{1}{c|}{Stop} \\
    \hline
    $V^{\pi}(s)$ &  3   &   3    &   3    &   4    &    5   & 6  \\
    \hline
    \end{tabular}
  \end{adjustbox}
\end{table}%

\part Old policy $\pi$ and has filled in parts of the updated policy $\pi'$ for you. If both \textit{Roll} and \textit{Stop} are viable new actions for a state, write down both \textit{Roll/Stop}. In this part as well, we have $\gamma = 1$.

\begin{table}[htbp]
  \centering
  \begin{adjustbox}{width=0.8\textwidth}
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    State & $s_1$ & $s_2$ & $s_3$ & \multicolumn{1}{c|}{$s_4$} & \multicolumn{1}{c|}{$s_5$} & \multicolumn{1}{c|}{$s_6$} \\
    \hline
    $\pi(s)$ & Roll  & Roll  & Stop  & \multicolumn{1}{c|}{Stop} & \multicolumn{1}{c|}{Stop} & \multicolumn{1}{c|}{Stop} \\
    \hline
    $\pi'(s)$ & Roll &   Roll    &    Roll/Stop   &    Stop   &   Stop   & Stop  \\
    \hline
    \end{tabular}
  \end{adjustbox}
\end{table}%

\part Is $\pi(s)$ from part (a) optimal? Explain why or why not.

$\pi(s)$ from part (a) is optimal. Explanation: $\pi'(s)$ from part (b) is almost the same as $\pi(s)$ from part (a). The only difference is the policies at $s_3$, but here the new policy results in the same utility as the old one does, which means $\pi(s)$ is as good as $\pi'(s)$. Hence, the policy has converged. As policy iteration converges to the optimal policy, $\pi(s)$ from part (a) is optimal.

\part Suppose that we were now working with some $\gamma\in [0, 1)$ and wanted to run \textbf{value iteration}. Select the one statement that would hold true at convergence, or write the correct answer next to Other if none of the options are correct.

\begin{enumerate}[A.]
	\item $V^*(s_i) = \max \Big\{ -1+\displaystyle\frac{i}{6},\ \sum_j \gamma V^*(s_j) \Big\}$
	\item $V^*(s_i) = \max \Big\{ i,\ \displaystyle\frac{1}{6}\big[-1+\sum_j \gamma V^*(s_j) \big] \Big\}$
	\item $V^*(s_i) = \max \Big\{ -\displaystyle\frac{1}{6}+i, \sum_j \gamma V^*(s_j) \Big\}$
	\item $V^*(s_i) = \max \Big\{ i,\ -\displaystyle\frac{1}{6} + \sum_j \gamma V^*(s_j) \Big\}$
	\item $V^*(s_i) = \displaystyle\frac{1}{6}  \sum_j \max \big\{ i,\ -1+\gamma V^*(s_j) \big\}$
	\item $V^*(s_i) = \displaystyle\frac{1}{6}  \sum_j \max \big\{-1+ i,\ \sum_k V^*(s_j) \big\}$
	\item $V^*(s_i) = \displaystyle\sum_j \max \Big\{-1+ i,\ \displaystyle\frac{1}{6} \gamma V^*(s_j) \Big\}$
	\item $V^*(s_i) = \displaystyle\sum_j \max \Big\{\displaystyle\frac{i}{6},\ -1+\gamma V^*(s_j) \Big\}$
	\item $V^*(s_i) = \max \Big\{i,\ -1+\displaystyle\frac{1}{6}\gamma \sum_j V^*(s_j) \Big\}$
	\item $V^*(s_i) = \displaystyle\sum_j \max \Big\{i,\ -\displaystyle\frac{1}{6}+\gamma V^*(s_j) \Big\}$
	\item $V^*(s_i) = \displaystyle\sum_j \max \Big\{-\displaystyle\frac{i}{6},\ -1+\gamma V^*(s_j) \Big\}$
\end{enumerate}
Solution: I

\end{parts}
\end{questions}

\end{document}
